

        컴퓨터 구조 원리 : 캐시와 파이프라인


이번시간에는 뜬금없긴하지만 컴퓨터 구조에 대해 알아보고 그 중에서도 캐시와 파이프라인에 대해 집중적으로 알아보겠습니다. 
왜 갑자기 컴퓨터 구조를 배우냐면 다음 주제인 메모리 모델을 이해하기 위한 기초 지식입니다. 


먼저 캐시 부터 시작하겠습니다. 

- 캐시 cache
실제 컴퓨터를 뜯어 보면 가장 중요하고 연산을 하는 장치인 CPU 와 저장공간인 RAM 이라는게 있습니다. 
RAM에 저장되어있는 데이터를 꺼내서 CPU에 주고 CPU에서 연산을 해줄겁니다. 우리가 배우던 스택메모리니, 데이터 영역이니 하는
것들이 다 RAM에 위치합니다.

그런데 실물 컴퓨터 보드를 보면 생각보다 CPU와 RAM사이에 거리가 꽤 있습니다. 그런데 프로그램을 실행하면서 RAM과 CPU 간의
통신이 수없이 일어날텐데 그때 마다 이 거리를 왕복해야하는게 비효율적으로 보입니다. 

CPU는 동작이 굉장히 빠른데 CPU혼자서 동작하는 경우는 거의 없고 저장장치 RAM에서 여러가지 데이터를 가져와서 동작합니다. 

대강 CPU가 4~50회 연산하는동안 데이터를 가져오는것은 한번정도 동작하기 때문에 데이터 전송하는 비용이 CPU연산에 비해 
되게 큽니다.

그래서 이 문제를 어떻게 우회 했냐면 '캐시'라는 개념을 도입했습니다. 
캐시는 임시저장소라고 보면되고 저장된 데이터가 영구히 보관되는건 아니고 일종의 메모장이라고 보면 되겠습니다. 

그리고 캐시는 하나만 있는것이 아니라 여러개를 두고 있습니다. 레지스터, L1 캐시, L2 캐시 등으로 이뤄져 있는데
각각이 피라미드 구조로 되어있고 앞의 캐시일 수록 용량이 적고 고급인 저장소입니다. 
이 캐시까지 뒤져서 필요한 데이터가 없아고 하면 그때서 RAM으로 가서데이터를 찾게됩니다. 
RAM에서 한번 가져온 데이터는 혹시 또 사용될 수 있으니 캐시에 저장하게되고 다음 CPU의 동작때 필요한 데이터를 찾으러 RAM으로 
바로 가지 않고 혹시 가까운 캐시에 있을 수 있으니 한번 찾아본 다음 없다면 RAM으로 갑니다. 

물론 캐시의 용량이 크지는 않기 때문에 프로그램이 실행되면서 용량이 다 차면 가장 오래되고 가장 사용 빈도수가 낮은 데이터 부터 
점차 비우면서 진행이 됩니다. 

캐시를 설계할때 두가지 철학을 고려합니다. 
1) TEMPORAL LOCALITY
- 시간적으로 보면, 방금 주문한 테이블에서 추가 주문이 나올 확률이 높다.
  방금 주문한걸 메모해 놓으면 편하지 않을까?
2) SPATIAL LOCALITY
- 공간적으로 봄ㄴ, 방금 주문한 사람 근처에 있는 사람이 추가 주문을 할 확률이 높다.
  방금 주문한 사람과 함석하고 있는 사람들의 주문 목록도 메모해 놓으면 편하지 않을까?

사용한지 두시간 지난 데이터 보다는 5초전에 사용한 데이터가 다시 사용할 확률이 높을것이고, 동떨어진 데이터 보다는 인접한 데이터를 
사용할 확률이 높을거라는 기준으로 캐시를 설계합니다. 

물론 왠만한 프로그래머가 직접 캐시를 만드는 일은 없고 사용만 할것이기는 한데 그래도 이런 기준들에 대해서는 알아두는게 좋을겁니다. 

이제 우리들의 컴퓨터에 있을 캐시를 좀 더 직접적으로 느껴보도록 실습해보겠습니다. 


int32 buffer[10000][10000];


int main()
{
	memset(buffer, 0, sizeof(buffer));

	{
		uint64 start = GetTickCount64();

		int64 sum = 0;

		for (int32 i = 0; i < 10000; i++)
			for (int32 j = 0; j < 10000; j++)
				sum += buffer[i][j];

		uint64 end = GetTickCount64();

		cout << "Elapsed Tick " << (end - start) << endl;
	}

	{
		uint64 start = GetTickCount64();

		int64 sum = 0;

		for (int32 i = 0; i < 10000; i++)
			for (int32 j = 0; j < 10000; j++)
				sum += buffer[j][i];

		uint64 end = GetTickCount64();

		cout << "Elapsed Tick " << (end - start) << endl;
	}
}

이게 실습해볼 코드입니다. buffer라는 변수는 컴퓨터 그래픽스에서 이미지를 숫자로 표현하는 방식입니다. 지금은 일단 이차 배열이라고 알아두겠습니다.
main 함수에서는 buffer 안에 혹시 다른 쓰레값이 들어 있을 수 있으니 범위의 모든데이터를 0으로 밀어버렸습니다. 

중괄호로 영역 두개를 집어 줬는데 각 영역에서 buffer를 이중 for문으로 순회를 하고 있습니다. 그런데 두 영역에 차이점은 buffer에 접근하는 순서가 
[i][j] 이냐 [j][i] 이냐의 차이입니다. 그리고 각 영역의 연산이 걸리는 Tick 을 구해서 출력합니다. 
컴퓨터 구조를 고려하지 않고 생각한다면 어떤 순서든간에 똑같이 끝나야 합니다. 

하지만 실질적으로 실행해보면 제 환경에서는 
187 틱과 1313 틱으로 현저하게 차이가 납니다. 
즉 첫번째 방법 i j 순으로 순회를 하는게 더욱 빠르다는걸 알 수 있습니다. 지금껏 이런차이는 고려하지 않았었습니다. 

그러면 왜 이런 차이가 나는지를 생각해보겠습니다. 

buffer 라는 변수 2차원 배열을 만들었는데 사람이 보기에 2차원 배열이지 사실 메모리 상으로 보면 1열로 늘어져 있습니다. 

[][][][][][] [][][][][][] [][][][][][] [][][][][][]  ...  이런식으로 되어 있습니다. 

이 상황에서 첫번째 방법을 보겠습니다. 

for (int32 i = 0; i < 10000; i++)
        for (int32 j = 0; j < 10000; j++)
                sum += buffer[i][j];

이중 for문을 도는데 j 부터 1만 까지 쭉 증가 한 후 i 가 하나 증가하고 j가 또 1만 쭉 증가하는 순서입니다. 
그러다 보니 buffer 의 실제 메모리 주소상에서 인접한 메모리를 쭉 훑고 지나가는 형태입니다. 

아까 얘기한데로 컴퓨터가 캐시라는것을 사용할때 buffer[0][0] 이라는 데이터를 가져온다고 했을때 정말 말 그대로 [0][0]의 int32 데이터 하나만 가져오는것이
아닙니다. SPATIAL LOCALITY 라는 철학으로 만들어진 캐시가 인접한 블록단위로 한번에 캐시로 긁어옵니다. 
그러면 다음 루프를 돌면서 다음으로 요구하는 데이터가 한번에 긁어온 데이터 안에 포함되는것을 '캐시 히트' 라고 합니다.
캐시 히트를 한경우에는 굳이 RAM까지 가서 다음 데이터를 가져오지 않고도 캐시에 가져온 데이터를 사용해도 되므로 CPU 리소스를 적게 먹을겁니다. 

이번에는 두번째 방법을 보겠습니다. 

for (int32 i = 0; i < 10000; i++)
        for (int32 j = 0; j < 10000; j++)
                sum += buffer[j][i];

buffer 의 접근하는 인덱스 순서가 j, i 순서가 되었을 뿐인데 순회를 하면서 처음 [0][0]의 데이터를 먼저 가져올건데 이때 인접한 데이터 블록을 
RAM에서 캐시로 가져올겁니다. 하지만 다음 루프인 [1][0] 에서는 캐시에 불러온 데이터 블럭이 아닌 RAM에 있는 데이터에 접근하고 있기 때문에 
캐시는 다음에 사용될거라고 예상해서 가져온 데이터는 무용지물이 되고 다시 RAM에서 다음 데이터 블럭을 긁어와야 하는 상황이 됩니다.
물론 0퍼센트로 캐시 히트가 되지 않는건 아니고 어느정도는 캐시 히트가 될 수 도 있지만 
확실히 연속된 데이터에 접근할때보다 느리게 동작하는것입니다. 



		파이프 라인 

이제 캐시에 이어 두번째 주제인 파이프라인 입니다. 
이번에는 이론보다 먼저 실습을 먼저 해보고 문제상황을 인지한 다음 이론을 보겠습니다. 


int32 x = 0;
int32 y = 0;
int32 r1 = 0;
int32 r2 = 0;

volatile bool ready;

void Thread_1()
{
	while (!ready)
		;

	y = 1;	// Store y
	r1 = x; // Load x
}

void Thread_2()
{
	while (!ready)
		;

	x = 1;	// Store x
	r2 = y; // Load y
}

int main()
{
	int32 count = 0;

	while (true)
	{
		ready = false;

		count++;

		x = y = r1 = r2 = 0;

		thread t1(Thread_1);
		thread t2(Thread_2);

		ready = true;

		t1.join();
		t2.join();

		if (r1 == 0 && r2 == 0)
			break;
	}

	cout << count << " 번만에 빠져나옴" << endl;
}

이런 코드를 실습 할겁니다. x, y, r1, r2 라는 int32 타입 변수들을 전역으로 만들었고 이 변수들을 
Thread_1, Thread_2 라는 함수안에서 값을 조정합니다. 이 두 함수를 t1, t2 라는 쓰레드를 만들어서 실행하도록 하였습니다. 
거기에 더해서 volatile bool 타입의 변수 ready 를 만들어서 t1, t2가 ready = false 일 동안 잠시 멈추고 
ready = true 가 되는 순간 동시에 실행되도록 시작 시점도 나름내로 맞췄습니다. 
이 쓰레드를 무한 루프 시키는데 만약 r1 과 r2 가 동시에 0이 되면 빠져나오게 했습니다. 

한번 실행해보면 각자 환경에 따라 어느정도 반복하다가 빠져나올 수도 있고 아니면 빠져나오지 못할 수도 있습니다. 
일단 강사님의 경우는 3000번 정도 반복후 빠져나오셨고 저는 빠져나오지 못하고 계속 반복했습니다. 

빠져나오는 경우가 이상한 건데 왜 이런 결과가 나오는지를 알아보겠습니다. 
Thread_1, Thread_2 함수의 내용에서 r1, r2가 동시에 0일 수가 있냐가 문제입니다.  

통상적인 프로그래밍에서 Thread_1, Thread_2가 진짜 거의 동시에 실행될겁니다. 그런데도 간발의 차이로 먼저 실행되는 함수가 있을겁니다.
간발의 차로 Thread_1가 먼저 실행되면 r2 가 1이 될거고 반대는 r1이 1이 될겁니다. 

결국 일반적으로 생각하면 break가 되는 조건이 통과될수 없다는 이야기인데 멀티쓰레드 환경에서 실습해보면 신기하게도 컴퓨터 환경에 따라
이게 조건이 통과되서 break가 되는 경우가 생기는 일이 있습니다. 
개발 환경에서는 정상작동하는데 사용자 환경에서는 이게 break가 된다면 개발자 입장에서 이런 문제가 있는지도 모르고 그냥 지나쳐버릴 수 밖에 
없습니다. 

이런 문제 상황을 알아 봤고 왜 이런 문제가 일어나는지를 알아볼것이고 해결 방안은 나중에 이후 강의에서 알아보겠습니다. 

문제점은 두가지 있습니다. '가시성' 과 '코드 재배치' 때문인데 

가시성은 무슨 얘기를 하고 있냐면 바로 이전에 캐시에 대해 배웠었는데 CPU가 어떤 값을 쓰거나 읽을때 곧이 곧대로 RAM에 있는 데이터를 읽지 않고 
먼저 캐시를 확인해서 이전에 가져온 데이터중 필요한 데이터가 있다면 가까운 데이터를 먼저 사용합니다. 

여기서 문제는 CPU에서 각 코어마다 별도의 캐시를 가지고 있습니다. 그렇다 함은 어떤 일이 일어나냐면 
t1 쓰레드에서 Thread_1를 실행하면서 y에 1이라는 값을 넣고 t2 쓰레드는 동시에 Thread_2를 실행하면서 r2 에 y값을 넣을건데 

이때 t1, t2가 y라는 변수의 값에 접근할때 매번 RAM까지 가서 원본 데이터를 참조하는게 아닐 수 있다는 겁니다. t1, t2가 각각 다른 코어를 사용할텐데 
각 코어가 RAM에 있는 y = 0 이라는 초기화 된 데이터를 각각 캐시에 복사한 다음 ready 가 true 가 되면서 
자기 캐시에 있는 y에 접근하는데 t1 쓰레드의 캐시에서는 y 를 1로 변경하지만 t2 쓰레드의 캐시에서는 y가 0 인채로 r2에 복사되는겁니다. 

이런문제가 싱글쓰레드 환경에서는 전혀 신경쓸 필요가 없었습니다. 단인 쓰레드이다보니 캐시도 한곳만 사용하고 먼저 실행된 함수의 메모리 변경이 
다른 함수에 확실히 적용되어 있을것이기 때문입니다. 

이런 문제를 '가시성' 이라고 합니다. 말 그대로 잘 보이느냐의 문제입니다. 서로 다른 캐시에 저장된 데이터를 참조하면 서로 어떤상태인지 잘 안보인다는겁니다.

가시성은 C# 기준으로 보면 volatile 키워드를 ready에 붙였을때 컴파일러 최적화도 막고 가시성 문제도 해결을 해주었습니다. 
하지만 C# 에서 volatile로 가시성 문제를 해결해도 여전히 break가 되는 상황이 있는데 그렇다는것은 가시성 말고 '코드 재배치' 문제도 중요하다는 겁니다. 

'코드 재배치'의 의미를 알기 위해서 먼저 알아야 할것이 있습니다. 
처음 프로그래밍을 배우면서 우리가 프로그래밍 언어로 코드를 작성하면 컴파일러가 코드를 로우레벨 언어로 쭉쭉 변환하면서 결국 컴퓨터의 언어인 binary 
까지 그대로 변환이 된다고 믿고 있었습니다. 

이건 사실 절반쯤만 진실입니다. 컴파일러는 우리가 작성한 코드를 읽어내면서 컴파일러 스스로 우리코드를 변경해서 변환을 하기도 합니다. 
우리가 작성한 코드보다 컴파일러 생각에 더 빠른 순서가 있다고 멋대로 코드를 수정한 다음 변환을 하는겁니다. 

컴파일러 입장에서는 먼저 멀티쓰레드환경을 고려하지않고 
void Thread_1()
{
	while (!ready)
		;

	r1 = x; // Load x
	y = 1;	// Store y
}
이렇게 로드를 먼저하고 스토어를 나중에 하는 방법이 더 빠르게 동작하겠다 생각하게되면 멋대로 수정을 해버립니다. 
왜냐면 사실 싱글 쓰레드 에서는 로드를 먼저 하나 스토어를 먼저하나 똑같으니까 컴파일러 편의에 따라 바꿔 버리는건데 

심지어 컴파일러가 코드를 수정하지 않고 그대로 변환 했다고 해도 CPU가 코드를 멋대로 수정하기도 합니다. 
실제로 디스어셈블리 코드를 확인해보면 컴파일러가 수정하지 않아도 break가 난다면 cpu에서 수정한것입니다. 

여태까지 멀티쓰레드를 몰랐을때는 이런 문제점들이 문제가 아니었습니다. 멀티쓰레드 환경에서 문제가 되는것입니다. 

그렇다면 CPU나 컴파일러를 만든 개발자들이 심술을 부려서 이런 문제가 생기는 것이 아니라 
뭔가 합리적인 이유가 있기 때문에 코드 재배치가 일어나는 걸 겁니다.

그래서 이 이유가 무엇인지를 이론적으로 알아보겠습니다. 


- 이론 

컴퓨터 구조중 파이프 라인이라는 것에 대해 알아봐야하는데 날것 그대로 공부하면 머리에 안들어 올테니 빨래에 비유해서 알아보겠습니다. 

빨래는 여러가지 단계로 이루어져 있습니다. 세탁기, 건조기, 다림질, 옷 개기 라는 단계들이 있고 
또 지금 빨래를 해야할 바구니가 여러개 있다고 하겠습니다.

이렇게 4단계를 거쳐야 빨래가 최종적으로 완성이 되는데 아주 단순하게 바구니 1번이 4단계를 다 끝낸 다음 바구니 2번을 빨기 시작하는것은 
시간 낭비가 심할 겁니다. 

바구니 1번이 세탁기가 끝나고 건조기를 들어가는 순간 세탁기에 다음 바구니를 넣어도 됩니다. 이런식으로 각 단계를 줄줄이 이어지게 
빨래가 진행되면 효율적으로 동작하는것 일겁니다. 

이렇게 병렬적으로 빨래를 하고 있는데 한가지 조건을 더 추가해보겠습니다. 만약 빨래 바구니가 여러개 있는데 이 바구니들에 들어 있는 
빨래의 양이 동등하지 않고 어떤 바구니는 꽉차있고 어느 바구니는 별로 없다고 하겠습니다. 

어떤 빨래감은 그냥 세탁기가 너무 오래걸리고 , 또 다른 빨래감은 소재가 까다로워서 다림질이 오래걸리기도 하는등 각각의 단계마다 
걸리는 시간이 다르기까지 하다면 

빨래감들을 빠는 순서를 잘 조절해서 실행해야 더욱 효율적으로 진행할 수 있을겁니다. 


이런 문제가 컴퓨터 CPU 에서도 똑같이 일어나고 있는겁니다. 
CPU도 마찬가지로 어떤 명령을 실행할때 한방에 뿅 실행되는게 아니라 Fetch, Decode, Execute, Wirte-back 이라는 4가지 단계를 거쳐서 
명령이 실행됩니다. 
먼저 명령을 가져오고 (Fetch) 가져온 명령을 해석을 하고 (Decode) 실질적인 실행을 한 다음(Execute) 실행한 결과물을 다시 제자리에 
가져다 둡니다.(Wirte-back)
이것을 CPU 파이프 라인이라고 하는겁니다. 

그래서 이 파이프라인에 일감들을 넣어주는데 빨래의 비유에서 보았듯이 일감의 양, 각 단계에 걸리는 속도를 고려해서 
일감의 위치를 뒤바꿔서 파이프라인에 넣어 줄 수 있습니다. 그래야 성능이 가장 최적화된 동작을 할 것입니다. 

하지만 지금 까지는 단일쓰레드 환경에서 공부를 했고 파이프라인도 단일쓰레드 환경에서는 문제가 없는 선에서 최적화를 하도록 되어 
있기 때문에 알아 채지 못하고 있던겁니다. 

서버 프로그래밍을 하면서 부터는 멀티쓰레드 환경에서 공부를 하고 있다 보니 문제가 됩니다. 


이런 문제가 있다고 하면 당연히 해결책도 이미 있을겁니다. C++11 기준으로 이전까지는 싱글쓰레드 기준으로 생각을했습니다. 
C++11 이후로는 멀티쓰레드 환경도 고려해서 많이 라이브러리 차원에서 지원해주기 시작했기 때문에 해결을 할 수 있게 되었습니다. 

지금까지 아무 의심없이 사용하던 컴파일러, CPU가 몰래 해오던 일을 알게 되었고 이후로 메모리 모델에 대해 배우면서 해결하는 방법도 
알아갈겁니다. 